{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6746de20-d093-4a16-860d-b9720a48907d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Diplomado en Ciencia de Datos\n",
    "M√≥dulo 2: Business Intelligence  \n",
    "## Tema 4: Consideraciones √âticas\n",
    "\n",
    "*Notebook by [Pedro V Hernandez Serrano](https://github.com/pedrohserrano)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f6c9b7-0d73-47a7-a665-f8699f86e329",
   "metadata": {},
   "source": [
    "---\n",
    "![](../img/header.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d5c027-0cda-4d2b-9ed2-9cde545746ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Consideraciones √©ticas en el uso de Algor√≠tmos de Similitud\n",
    "\n",
    "Los algoritmos de similitud miden cu√°n parecidos son dos objetos en funci√≥n de caracter√≠sticas espec√≠ficas, como en las distancias Euclidiana, Manhattan o la Similitud Coseno. Sin embargo, **es importante considerar el contexto y las implicaciones √©ticas al definir \"similitud\"**. La interpretaci√≥n de similitud puede ser problem√°tica cuando se asume que caracter√≠sticas seleccionadas (como ingresos o nivel educativo) son suficientes para capturar la esencia de los datos. En aplicaciones como contrataci√≥n o an√°lisis de cr√©dito, esta suposici√≥n puede llevar a decisiones injustas o discriminatorias.\n",
    "\n",
    "La relevancia contextual tambi√©n es clave: **lo que define similitud en un contexto (como investigaci√≥n m√©dica) puede no ser adecuado en otro (como marketing), y no considerar estas diferencias puede llevar a conclusiones err√≥neas**. Finalmente, el impacto en la toma de decisiones es cr√≠tico. Los algoritmos de similitud influyen en decisiones importantes y deben evitar causar da√±o a grupos o individuos. Asumir que dos objetos similares en un espacio matem√°tico son iguales en la vida real puede tener graves consecuencias si no se toma en cuenta el contexto.\n",
    "\n",
    "Al utilizar estos algoritmos, es fundamental reflexionar sobre el impacto de las decisiones basadas en ellos para garantizar que no refuercen desigualdades ni causen da√±os involuntarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c003aa50-75b6-4d68-a02c-f826f0bfaca8",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Original blog implementing the most popular similarity algorithms**  \n",
    "\n",
    "‚úÖ [dataaspirant.com](https://dataaspirant.com/five-most-popular-similarity-measures-implementation-in-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69d20a1-a8c6-4f4f-a828-5b9611491795",
   "metadata": {},
   "source": [
    "![](https://i0.wp.com/dataaspirant.com/wp-content/uploads/2015/04/cover_post_final.png?w=1000&ssl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe9da70-42d9-4f73-8f37-3cbfc803512c",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# EJERCICIO 1\n",
    "\n",
    "- Desarrolla una funcion en Python que calcule la [distancia euclidiana](https://www.google.com/search?sca_esv=08fa89593227d7c4&sca_upv=1&sxsrf=ADLYWILxL5ZB2RJ2Ur94L62oXEBk5CorNg:1725814856550&q=euclidean+distance+formula&source=lnms&fbs=AEQNm0Aa4sjWe7Rqy32pFwRj0UkWd8nbOJfsBGGB5IQQO6L3J_86uWOeqwdnV0yaSF-x2joQcoZ-0Q2Udkt2zEybT7HdNV1kobqvEwEVRYBCltlBtd67W1w89UVGf7QOAkvJWcD0qzhOT-WizJ4nyd1QOGdS_33AboApQh8NDOYXDdgzT_HrFjEfW4zkALzuIfB9KacfX-PQ&sa=X&ved=2ahUKEwiMteOr6bOIAxVX9rsIHW25HdMQ0pQJegQIDRAB&biw=1920&bih=974&dpr=1)\n",
    "- Prueba la funci√≥n con los siguientes vectores:  \n",
    " `v1 = [0,1,2,5,6]`  \n",
    " `v2 = [0,2,3,5,7]`  \n",
    "- El resultado debe ser aprox `1.73`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ab60aef-4c0c-40c2-a54c-acbbd7fff2f3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7320508075688772\n"
     ]
    }
   ],
   "source": [
    "# def euclidean_distance(self, x, y):\n",
    "class Distancia:\n",
    "    def euclidean_distance(self, x, y):\n",
    "        suma_cuadrados = 0\n",
    "        for i in range(len(x)):\n",
    "            suma_cuadrados += (x[i] - y[i]) ** 2\n",
    "        return suma_cuadrados ** 0.5 #aqui me lo devuelve\n",
    "\n",
    "# Prueba \n",
    "dist = Distancia()\n",
    "v1 = [0, 1, 2, 5, 6]\n",
    "v2 = [0, 2, 3, 5, 7]\n",
    "\n",
    "resultado = dist.euclidean_distance(v1, v2)\n",
    "print(resultado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b787db-0c79-404d-bd2c-e2a4f9ebf65c",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# EJERCICIO 2\n",
    "\n",
    "- Desarrolla una funcion en Python que calcule la [distancia manhattan](https://www.google.com/search?q=manhattan+distance+formula&sca_esv=08fa89593227d7c4&sca_upv=1&biw=1920&bih=974&ei=V9jdZtmAEoiwi-gP-9nf-AI&oq=euclidean+distance+formula&gs_lp=Egxnd3Mtd2l6LXNlcnAiGmV1Y2xpZGVhbiBkaXN0YW5jZSBmb3JtdWxhKgIIADIKEAAYsAMY1gQYRzIKEAAYsAMY1gQYRzIKEAAYsAMY1gQYRzIKEAAYsAMY1gQYRzIKEAAYsAMY1gQYRzIKEAAYsAMY1gQYRzIKEAAYsAMY1gQYRzIKEAAYsAMY1gQYRzINEAAYgAQYsAMYQxiKBTINEAAYgAQYsAMYQxiKBUiLElAAWABwAngBkAEAmAEAoAEAqgEAuAEDyAEAmAICoAIQmAMAiAYBkAYKkgcBMqAHAA&sclient=gws-wiz-serp)\n",
    "- Prueba la funci√≥n con los siguientes vectores:  \n",
    " `v1 = [0,1,2,5,6]`  \n",
    " `v2 = [0,2,3,5,7]`  \n",
    "- El resultado debe ser `3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be069a86-c57e-4645-84bf-a62d097843af",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# def manhattan_distance(self, x, y):       #basado en objeto\n",
    "\n",
    "class Distancia:\n",
    "    def manhattan_distance(self, x, y):\n",
    "        suma_abs = 0\n",
    "        for i in range(len(x)):\n",
    "            suma_abs += abs(x[i] - y[i])\n",
    "        return suma_abs\n",
    "\n",
    "dist = Distancia()\n",
    "v1 = [0, 1, 2, 5, 6]\n",
    "v2 = [0, 2, 3, 5, 7]\n",
    "\n",
    "resultado = dist.manhattan_distance(v1, v2)\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c971d7-29cb-472d-a0f2-cd696de4cbd3",
   "metadata": {},
   "source": [
    "---\n",
    "# EJERCICIO 3 (Opcional)\n",
    "\n",
    "- Desarrolla una funcion en Python que calcule la [distancia coseno](https://en.wikipedia.org/wiki/Cosine_similarity)\n",
    "- Prueba la funci√≥n con los siguientes vectores:  \n",
    " `v1 = [0,1,2,5,6]`  \n",
    " `v2 = [0,2,3,5,7]`  \n",
    "- El resultado debe ser `0.99`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03191241-8eb2-43d3-adf7-22198d76228a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La distancia coseno es: 0.99\n"
     ]
    }
   ],
   "source": [
    "import math      #esto es para escalada de datos y predicciones \n",
    "\n",
    "class Distancia:\n",
    "    def cosine_similarity(self, x, y):\n",
    "    \n",
    "        producto_punto = sum(x[i] * y[i] for i in range(len(x)))\n",
    "        \n",
    "        \n",
    "        magnitud_x = math.sqrt(sum(x[i] ** 2 for i in range(len(x))))\n",
    "        magnitud_y = math.sqrt(sum(y[i] ** 2 for i in range(len(y))))\n",
    "        \n",
    "        # similitud \n",
    "        if magnitud_x == 0 or magnitud_y == 0:\n",
    "            return 0  # Si alguna magnitud es 0, no hay similitud\n",
    "        coseno_similitud = producto_punto / (magnitud_x * magnitud_y)\n",
    "        \n",
    "        \n",
    "        return round(coseno_similitud, 2)\n",
    "\n",
    "\n",
    "dist = Distancia()\n",
    "v1 = [0, 1, 2, 5, 6]\n",
    "v2 = [0, 2, 3, 5, 7]\n",
    "\n",
    "resultado = dist.cosine_similarity(v1, v2)\n",
    "print(f\"La distancia coseno es: {resultado:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6abe64-05cc-4888-a0da-5912284421f4",
   "metadata": {},
   "source": [
    "## Constructing a Similarity Network from a Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f46078-e9f5-4819-bc1a-1a2512feb597",
   "metadata": {},
   "source": [
    "The idea is to compute one similarity alorithm N*N times across the dataset, then take the top M similar records and constructa network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c586de43-c77d-4ccb-bd0b-1387244501ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>continent</th>\n",
       "      <th>year</th>\n",
       "      <th>lifeExp</th>\n",
       "      <th>pop</th>\n",
       "      <th>gdpPercap</th>\n",
       "      <th>iso_alpha</th>\n",
       "      <th>iso_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>1952</td>\n",
       "      <td>28.801</td>\n",
       "      <td>8425333</td>\n",
       "      <td>779.445314</td>\n",
       "      <td>AFG</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>1957</td>\n",
       "      <td>30.332</td>\n",
       "      <td>9240934</td>\n",
       "      <td>820.853030</td>\n",
       "      <td>AFG</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>1962</td>\n",
       "      <td>31.997</td>\n",
       "      <td>10267083</td>\n",
       "      <td>853.100710</td>\n",
       "      <td>AFG</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>1967</td>\n",
       "      <td>34.020</td>\n",
       "      <td>11537966</td>\n",
       "      <td>836.197138</td>\n",
       "      <td>AFG</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>1972</td>\n",
       "      <td>36.088</td>\n",
       "      <td>13079460</td>\n",
       "      <td>739.981106</td>\n",
       "      <td>AFG</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country continent  year  lifeExp       pop   gdpPercap iso_alpha  \\\n",
       "0  Afghanistan      Asia  1952   28.801   8425333  779.445314       AFG   \n",
       "1  Afghanistan      Asia  1957   30.332   9240934  820.853030       AFG   \n",
       "2  Afghanistan      Asia  1962   31.997  10267083  853.100710       AFG   \n",
       "3  Afghanistan      Asia  1967   34.020  11537966  836.197138       AFG   \n",
       "4  Afghanistan      Asia  1972   36.088  13079460  739.981106       AFG   \n",
       "\n",
       "   iso_num  \n",
       "0        4  \n",
       "1        4  \n",
       "2        4  \n",
       "3        4  \n",
       "4        4  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"../data/gapminder_data_world_health.csv\")\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dfd4f6-35ef-463c-b50c-68cde6694515",
   "metadata": {},
   "source": [
    "---\n",
    "# EJERCICIO 4\n",
    "\n",
    "Con los datos de `gapminder_data_world_health.csv` utiliza el siguiente subset de la tabla como se muestra a continuaci√≥n (es un query de el a√±o 2007 en el que se tiene la esperanza de vida y la poblaci√≥n indexada por pa√≠s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1466fb47-75cc-44eb-880f-cab87172599e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = dataset[dataset['year'] == 2007].set_index('country')\n",
    "df = df[['lifeExp', 'pop']]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be52fdd-4ceb-4167-b5d9-b3595b80119c",
   "metadata": {},
   "source": [
    "- **Utiliza el m√©todo Min-Max** para normalizar los vectores de Esperanza de vida y de Poblaci√≥n, una vez que apliquemos las funciones de similitud es mejor tener los vectores en las misma escala: [Ejemplo aqu√≠](https://www.geeksforgeeks.org/data-normalization-with-pandas/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "219df90b-4913-42d9-96ee-761f543bed78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        country   lifeExp       pop\n",
      "11  Afghanistan  0.098046  0.024035\n",
      "23      Albania  0.856246  0.002579\n",
      "35      Algeria  0.760363  0.025130\n",
      "47       Angola  0.072528  0.009269\n",
      "59    Argentina  0.830589  0.030416\n",
      "Matriz de similitud coseno entre esperanza de vida y poblaci√≥n:\n",
      "[[0.27973128]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# apply normalization\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "dataset = pd.read_csv(\"../data/gapminder_data_world_health.csv\")\n",
    "\n",
    "data_2007 = dataset[dataset['year'] == 2007]\n",
    "\n",
    "data_subset= data_2007[['country', 'lifeExp', 'pop']]\n",
    "\n",
    "# Normalizamos datos\n",
    "scaler = MinMaxScaler()\n",
    "data_subset.loc[:,['lifeExp', 'pop']] = scaler.fit_transform(data_subset[['lifeExp', 'pop']])\n",
    "\n",
    "print(data_subset.head())\n",
    "\n",
    "# datos normalizados a matrices\n",
    "lifeExp_vector = data_subset[['lifeExp']].values\n",
    "pop_vector = data_subset[['pop']].values\n",
    "\n",
    "# similitud coseno entre los vectores de esperanza de vida y poblaci√≥n\n",
    "similarity_matrix = cosine_similarity(lifeExp_vector.T, pop_vector.T)\n",
    "\n",
    "print(\"Matriz de similitud coseno entre esperanza de vida y poblaci√≥n:\")\n",
    "print(similarity_matrix)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#.loc[:,['lifeExp', si lo quito error:El SettingWithCopyWarning ocurre porque est√°s \n",
    "#modificando un DataFrame que es una vista de otro DataFrame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f428dd4-5cff-4f6d-9f4c-fbc79bd19261",
   "metadata": {},
   "source": [
    "---\n",
    "# EJERCICIO 5\n",
    "\n",
    "**Crea un un nuevo dataset con los 3 paises m√°s cercanos a cada pa√≠s**, es decir un **dataset de \n",
    "distancias**, el resultado que se busca es como se ve en la imagen. Utilizar√°s el subset normalizado (ejercicio 4) para ello y una de las funciones que creaste (manhattan, euclideana o coseno)\n",
    "\n",
    "![](../img/distancias.png)\n",
    "\n",
    "**C√≥mo crear el dataset de distancias?**\n",
    "- Por cada pa√≠s, necesitas calcular la distancia entre √©l y todos los dem√°s pa√≠ses en el DataFrame. Evitando comparar cada pa√≠s consigo mismo.\n",
    "- Cada iteraci√≥n corresponde a cada pa√≠s comparado, el pa√≠s al que se le calcul√≥ la distancia, y la distancia entre ambos. (hint: una lista de tuplas o diccionarios puede ser √∫til aqu√≠)\n",
    "- Despu√©s de hacer todas las comparaciones, convierte los resultados en un DataFrame con tres columnas: `nodeA`, `nodeB`, `distance`.\n",
    "- Para cada pa√≠s (nodeA), agrupa las distancias calculadas y ord√©nalas de menor a mayor. Se quiere unicamente los tres pa√≠ses m√°s cercanos a cada pa√≠s (distancias m√°s peque√±as para cada pa√≠s)\n",
    "- No olvides revisar los resultados una vez que tengas la tabla final con los 3 pa√≠ses m√°s cercanos para cada pa√≠s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca3cb727-0f31-4838-91ab-2118238744eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        country   lifeExp       pop\n",
      "11  Afghanistan  0.098046  0.024035\n",
      "23      Albania  0.856246  0.002579\n",
      "35      Algeria  0.760363  0.025130\n",
      "47       Angola  0.072528  0.009269\n",
      "59    Argentina  0.830589  0.030416\n",
      "         nodeA                     nodeB  distance\n",
      "0  Afghanistan                  Zimbabwe  0.022782\n",
      "1  Afghanistan                    Angola  0.040284\n",
      "2  Afghanistan  Central African Republic  0.042111\n",
      "3      Albania                   Uruguay  0.001023\n",
      "4      Albania                   Reunion  0.002567\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## for loop in all countries applying 1 distance function\n",
    "## dataframe _____\n",
    "## top 3 distances: Zimbabwe,Angola y Rep√∫blica central de Africa para Afganistan\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#original\n",
    "dataset = pd.read_csv(\"../data/gapminder_data_world_health.csv\")\n",
    "\n",
    "# a√±o 2007\n",
    "data_subset = dataset[dataset['year'] == 2007][['country', 'lifeExp', 'pop']]\n",
    "\n",
    "#distancia Manhattan\n",
    "def manhattan_distance(vec1, vec2):\n",
    "    return np.sum(np.abs(vec1 - vec2))\n",
    "\n",
    "#Normalizamos\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "data_subset[['lifeExp', 'pop']] = scaler.fit_transform(data_subset[['lifeExp', 'pop']])\n",
    "\n",
    "print(data_subset.head())\n",
    "\n",
    "data_subset.to_csv('normalized_data_2007.csv', index=False) #para guardar csv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def manhattan_distance(vec1, vec2):\n",
    "    return np.sum(np.abs(vec1 - vec2))\n",
    "\n",
    "\n",
    "data_subset = pd.read_csv(\"normalized_data_2007.csv\")  #archivo normalizado\n",
    "\n",
    "\n",
    "lifeExp_vector = data_subset[['lifeExp']].values\n",
    "pop_vector = data_subset[['pop']].values\n",
    "\n",
    "#lista para almacenar las distancias\n",
    "distances = []\n",
    "\n",
    "for i, (lifeExp_i, pop_i) in enumerate(zip(lifeExp_vector, pop_vector)):\n",
    "    for j, (lifeExp_j, pop_j) in enumerate(zip(lifeExp_vector, pop_vector)):\n",
    "        if i != j:  #evitar que sean los mismos\n",
    "            distance = manhattan_distance(lifeExp_i, lifeExp_j) + manhattan_distance(pop_i, pop_j)\n",
    "            distances.append({\n",
    "                'nodeA': data_subset.iloc[i]['country'],\n",
    "                'nodeB': data_subset.iloc[j]['country'],\n",
    "                'distance': distance\n",
    "            })\n",
    "\n",
    "#DataFrame de distancias\n",
    "distances_df = pd.DataFrame(distances)\n",
    "\n",
    "# Encontrar los 3 pa√≠ses m√°s cercanos para cada pa√≠s\n",
    "closest_countries = distances_df.groupby('nodeA').apply(\n",
    "    lambda x: x.nsmallest(3, 'distance')\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(closest_countries.head())\n",
    "\n",
    "closest_countries.to_csv('closest_countries_manhattan.csv', index=False) #guardemos\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29045c2c-fa13-4dd2-b1fe-36425ba8ed5f",
   "metadata": {},
   "source": [
    "---\n",
    "# EJERCICIO 6\n",
    "\n",
    "Reproduce el siguiente script.   \n",
    "El script utiliza la libreria `networkx` y `plotly` para visualizar una gr√°fica de red (network plot) visualizando la distancia (similitud) entre los paises basado en esperanza de vida y poblaci√≥n.  \n",
    "\n",
    "**Nota:** Si el dataframe del ejercicio anterior no es correcto, la visualizaci√≥n no va a funcionar.\n",
    "\n",
    "**Responde lo siguiente:**\n",
    "- Cuales son los pa√≠ses m√°s similares a M√©xico?\n",
    "- Explica cuales ser√≠an las consideraciones √©ticas al decir que M√©xico es similar a esos pa√≠ses en el contexto de las variables `lifeExp` y `pop`, dando contexto de el a√±o seleccionado y del significado de la funcion de similitud utilizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2811b909-687b-40a4-b72a-c5c970de0136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "distances = [\n",
    "    {'nodeA': 'Afghanistan', 'nodeB': 'Zimbabwe', 'distance': 0.022782},\n",
    "    {'nodeA': 'Afghanistan', 'nodeB': 'Angola', 'distance': 0.040284},\n",
    "    {'nodeA': 'Afghanistan', 'nodeB': 'Central African Republic', 'distance': 0.042111},\n",
    "    {'nodeA': 'Albania', 'nodeB': 'Uruguay', 'distance': 0.001023},\n",
    "    {'nodeA': 'Albania', 'nodeB': 'Reunion', 'distance': 0.002567},\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "df_network = pd.DataFrame(distances)\n",
    "print(df_network.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130f8a5b-2662-4421-a2c7-e5252daeb234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "#Empty graph object\n",
    "g = nx.Graph()\n",
    "\n",
    "# Adding all nodes\n",
    "g.add_nodes_from(list(df_network.nodeA.unique()))\n",
    "\n",
    "# Adding all edges\n",
    "edges_list = [(row[1][0],row[1][1],row[1][2]) for row in df_network.iterrows()]\n",
    "g.add_weighted_edges_from(edges_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b656ac48-9df3-4989-b303-1ddc99707d49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "pos = nx.spring_layout(g, dim=2, iterations=10, weight='weight', scale=2)\n",
    "\n",
    "# Create a DataFrame for nodes\n",
    "node_x = []\n",
    "node_y = []\n",
    "for node in g.nodes():\n",
    "    x, y = pos[node]\n",
    "    node_x.append(x)\n",
    "    node_y.append(y)\n",
    "\n",
    "# Create a DataFrame for edges\n",
    "edge_x = []\n",
    "edge_y = []\n",
    "for edge in g.edges():\n",
    "    x0, y0 = pos[edge[0]]\n",
    "    x1, y1 = pos[edge[1]]\n",
    "    edge_x.append(x0)\n",
    "    edge_x.append(x1)\n",
    "    edge_x.append(None)  # For a break between edges\n",
    "    edge_y.append(y0)\n",
    "    edge_y.append(y1)\n",
    "    edge_y.append(None)  # For a break between edges\n",
    "\n",
    "# Create the plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add edges to the plot\n",
    "fig.add_trace(go.Scatter(x=edge_x, y=edge_y,\n",
    "                         line=dict(width=0.5, color='gray'),\n",
    "                         hoverinfo='none',\n",
    "                         mode='lines'))\n",
    "\n",
    "# Add nodes to the plot\n",
    "fig.add_trace(go.Scatter(x=node_x, y=node_y,\n",
    "                         mode='markers+text',  # Show both markers and labels\n",
    "                         marker=dict(size=10, color='#9500ff'),\n",
    "                         text=[str(node) for node in g.nodes()],  # Add node labels\n",
    "                         textposition='top center',\n",
    "                         hoverinfo='text'))\n",
    "\n",
    "# Update layout for better aesthetics and set figure size\n",
    "fig.update_layout(\n",
    "    showlegend=False,\n",
    "    xaxis=dict(showgrid=False, zeroline=False),\n",
    "    yaxis=dict(showgrid=False, zeroline=False),\n",
    "    plot_bgcolor='white',\n",
    "    width=1200,  # Set the figure width\n",
    "    height=1500   # Set the figure height\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f8676a-e0b6-4721-bd82-336ae1b276a4",
   "metadata": {},
   "source": [
    "La gr√°fica debe quedar como se ve en la imagen.   \n",
    "![](../img/countries_similarities.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4de1c4-219e-42d1-8679-f70bce01b0d9",
   "metadata": {},
   "source": [
    "## üéâüéâ Congrats!!  \n",
    "\n",
    "## You've finished the notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
