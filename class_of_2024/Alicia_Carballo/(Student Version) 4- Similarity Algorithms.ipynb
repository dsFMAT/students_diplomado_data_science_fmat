{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6746de20-d093-4a16-860d-b9720a48907d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Diplomado en Ciencia de Datos\n",
    "Módulo 2: Business Intelligence  \n",
    "## Tema 4: Consideraciones Éticas\n",
    "\n",
    "*Notebook by [Pedro V Hernandez Serrano](https://github.com/pedrohserrano)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f6c9b7-0d73-47a7-a665-f8699f86e329",
   "metadata": {},
   "source": [
    "---\n",
    "![](../img/header.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d5c027-0cda-4d2b-9ed2-9cde545746ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Consideraciones éticas en el uso de Algorítmos de Similitud\n",
    "\n",
    "Los algoritmos de similitud miden cuán parecidos son dos objetos en función de características específicas, como en las distancias Euclidiana, Manhattan o la Similitud Coseno. Sin embargo, **es importante considerar el contexto y las implicaciones éticas al definir \"similitud\"**. La interpretación de similitud puede ser problemática cuando se asume que características seleccionadas (como ingresos o nivel educativo) son suficientes para capturar la esencia de los datos. En aplicaciones como contratación o análisis de crédito, esta suposición puede llevar a decisiones injustas o discriminatorias.\n",
    "\n",
    "La relevancia contextual también es clave: **lo que define similitud en un contexto (como investigación médica) puede no ser adecuado en otro (como marketing), y no considerar estas diferencias puede llevar a conclusiones erróneas**. Finalmente, el impacto en la toma de decisiones es crítico. Los algoritmos de similitud influyen en decisiones importantes y deben evitar causar daño a grupos o individuos. Asumir que dos objetos similares en un espacio matemático son iguales en la vida real puede tener graves consecuencias si no se toma en cuenta el contexto.\n",
    "\n",
    "Al utilizar estos algoritmos, es fundamental reflexionar sobre el impacto de las decisiones basadas en ellos para garantizar que no refuercen desigualdades ni causen daños involuntarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c003aa50-75b6-4d68-a02c-f826f0bfaca8",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Original blog implementing the most popular similarity algorithms**  \n",
    "\n",
    "✅ [dataaspirant.com](https://dataaspirant.com/five-most-popular-similarity-measures-implementation-in-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69d20a1-a8c6-4f4f-a828-5b9611491795",
   "metadata": {},
   "source": [
    "![](https://i0.wp.com/dataaspirant.com/wp-content/uploads/2015/04/cover_post_final.png?w=1000&ssl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe9da70-42d9-4f73-8f37-3cbfc803512c",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# EJERCICIO 1\n",
    "\n",
    "- Desarrolla una funcion en Python que calcule la [distancia euclidiana](https://www.google.com/search?sca_esv=08fa89593227d7c4&sca_upv=1&sxsrf=ADLYWILxL5ZB2RJ2Ur94L62oXEBk5CorNg:1725814856550&q=euclidean+distance+formula&source=lnms&fbs=AEQNm0Aa4sjWe7Rqy32pFwRj0UkWd8nbOJfsBGGB5IQQO6L3J_86uWOeqwdnV0yaSF-x2joQcoZ-0Q2Udkt2zEybT7HdNV1kobqvEwEVRYBCltlBtd67W1w89UVGf7QOAkvJWcD0qzhOT-WizJ4nyd1QOGdS_33AboApQh8NDOYXDdgzT_HrFjEfW4zkALzuIfB9KacfX-PQ&sa=X&ved=2ahUKEwiMteOr6bOIAxVX9rsIHW25HdMQ0pQJegQIDRAB&biw=1920&bih=974&dpr=1)\n",
    "- Prueba la función con los siguientes vectores:  \n",
    " `v1 = [0,1,2,5,6]`  \n",
    " `v2 = [0,2,3,5,7]`  \n",
    "- El resultado debe ser aprox `1.73`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ab60aef-4c0c-40c2-a54c-acbbd7fff2f3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7320508075688772\n"
     ]
    }
   ],
   "source": [
    "# def euclidean_distance(self, x, y):\n",
    "class Distancia:\n",
    "    def euclidean_distance(self, x, y):\n",
    "        suma_cuadrados = 0\n",
    "        for i in range(len(x)):\n",
    "            suma_cuadrados += (x[i] - y[i]) ** 2\n",
    "        return suma_cuadrados ** 0.5 #aqui me lo devuelve\n",
    "\n",
    "# Prueba \n",
    "dist = Distancia()\n",
    "v1 = [0, 1, 2, 5, 6]\n",
    "v2 = [0, 2, 3, 5, 7]\n",
    "\n",
    "resultado = dist.euclidean_distance(v1, v2)\n",
    "print(resultado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b787db-0c79-404d-bd2c-e2a4f9ebf65c",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# EJERCICIO 2\n",
    "\n",
    "- Desarrolla una funcion en Python que calcule la [distancia manhattan](https://www.google.com/search?q=manhattan+distance+formula&sca_esv=08fa89593227d7c4&sca_upv=1&biw=1920&bih=974&ei=V9jdZtmAEoiwi-gP-9nf-AI&oq=euclidean+distance+formula&gs_lp=Egxnd3Mtd2l6LXNlcnAiGmV1Y2xpZGVhbiBkaXN0YW5jZSBmb3JtdWxhKgIIADIKEAAYsAMY1gQYRzIKEAAYsAMY1gQYRzIKEAAYsAMY1gQYRzIKEAAYsAMY1gQYRzIKEAAYsAMY1gQYRzIKEAAYsAMY1gQYRzIKEAAYsAMY1gQYRzIKEAAYsAMY1gQYRzINEAAYgAQYsAMYQxiKBTINEAAYgAQYsAMYQxiKBUiLElAAWABwAngBkAEAmAEAoAEAqgEAuAEDyAEAmAICoAIQmAMAiAYBkAYKkgcBMqAHAA&sclient=gws-wiz-serp)\n",
    "- Prueba la función con los siguientes vectores:  \n",
    " `v1 = [0,1,2,5,6]`  \n",
    " `v2 = [0,2,3,5,7]`  \n",
    "- El resultado debe ser `3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be069a86-c57e-4645-84bf-a62d097843af",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# def manhattan_distance(self, x, y):       #basado en objeto\n",
    "\n",
    "class Distancia:\n",
    "    def manhattan_distance(self, x, y):\n",
    "        suma_abs = 0\n",
    "        for i in range(len(x)):\n",
    "            suma_abs += abs(x[i] - y[i])\n",
    "        return suma_abs\n",
    "\n",
    "dist = Distancia()\n",
    "v1 = [0, 1, 2, 5, 6]\n",
    "v2 = [0, 2, 3, 5, 7]\n",
    "\n",
    "resultado = dist.manhattan_distance(v1, v2)\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c971d7-29cb-472d-a0f2-cd696de4cbd3",
   "metadata": {},
   "source": [
    "---\n",
    "# EJERCICIO 3 (Opcional)\n",
    "\n",
    "- Desarrolla una funcion en Python que calcule la [distancia coseno](https://en.wikipedia.org/wiki/Cosine_similarity)\n",
    "- Prueba la función con los siguientes vectores:  \n",
    " `v1 = [0,1,2,5,6]`  \n",
    " `v2 = [0,2,3,5,7]`  \n",
    "- El resultado debe ser `0.99`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03191241-8eb2-43d3-adf7-22198d76228a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La distancia coseno es: 0.99\n"
     ]
    }
   ],
   "source": [
    "import math      #esto es para escalada de datos y predicciones \n",
    "\n",
    "class Distancia:\n",
    "    def cosine_similarity(self, x, y):\n",
    "    \n",
    "        producto_punto = sum(x[i] * y[i] for i in range(len(x)))\n",
    "        \n",
    "        \n",
    "        magnitud_x = math.sqrt(sum(x[i] ** 2 for i in range(len(x))))\n",
    "        magnitud_y = math.sqrt(sum(y[i] ** 2 for i in range(len(y))))\n",
    "        \n",
    "        # similitud \n",
    "        if magnitud_x == 0 or magnitud_y == 0:\n",
    "            return 0  # Si alguna magnitud es 0, no hay similitud\n",
    "        coseno_similitud = producto_punto / (magnitud_x * magnitud_y)\n",
    "        \n",
    "        \n",
    "        return round(coseno_similitud, 2)\n",
    "\n",
    "\n",
    "dist = Distancia()\n",
    "v1 = [0, 1, 2, 5, 6]\n",
    "v2 = [0, 2, 3, 5, 7]\n",
    "\n",
    "resultado = dist.cosine_similarity(v1, v2)\n",
    "print(f\"La distancia coseno es: {resultado:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6abe64-05cc-4888-a0da-5912284421f4",
   "metadata": {},
   "source": [
    "## Constructing a Similarity Network from a Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f46078-e9f5-4819-bc1a-1a2512feb597",
   "metadata": {},
   "source": [
    "The idea is to compute one similarity alorithm N*N times across the dataset, then take the top M similar records and constructa network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c586de43-c77d-4ccb-bd0b-1387244501ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>continent</th>\n",
       "      <th>year</th>\n",
       "      <th>lifeExp</th>\n",
       "      <th>pop</th>\n",
       "      <th>gdpPercap</th>\n",
       "      <th>iso_alpha</th>\n",
       "      <th>iso_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>1952</td>\n",
       "      <td>28.801</td>\n",
       "      <td>8425333</td>\n",
       "      <td>779.445314</td>\n",
       "      <td>AFG</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>1957</td>\n",
       "      <td>30.332</td>\n",
       "      <td>9240934</td>\n",
       "      <td>820.853030</td>\n",
       "      <td>AFG</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>1962</td>\n",
       "      <td>31.997</td>\n",
       "      <td>10267083</td>\n",
       "      <td>853.100710</td>\n",
       "      <td>AFG</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>1967</td>\n",
       "      <td>34.020</td>\n",
       "      <td>11537966</td>\n",
       "      <td>836.197138</td>\n",
       "      <td>AFG</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>1972</td>\n",
       "      <td>36.088</td>\n",
       "      <td>13079460</td>\n",
       "      <td>739.981106</td>\n",
       "      <td>AFG</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country continent  year  lifeExp       pop   gdpPercap iso_alpha  \\\n",
       "0  Afghanistan      Asia  1952   28.801   8425333  779.445314       AFG   \n",
       "1  Afghanistan      Asia  1957   30.332   9240934  820.853030       AFG   \n",
       "2  Afghanistan      Asia  1962   31.997  10267083  853.100710       AFG   \n",
       "3  Afghanistan      Asia  1967   34.020  11537966  836.197138       AFG   \n",
       "4  Afghanistan      Asia  1972   36.088  13079460  739.981106       AFG   \n",
       "\n",
       "   iso_num  \n",
       "0        4  \n",
       "1        4  \n",
       "2        4  \n",
       "3        4  \n",
       "4        4  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"../data/gapminder_data_world_health.csv\")\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dfd4f6-35ef-463c-b50c-68cde6694515",
   "metadata": {},
   "source": [
    "---\n",
    "# EJERCICIO 4\n",
    "\n",
    "Con los datos de `gapminder_data_world_health.csv` utiliza el siguiente subset de la tabla como se muestra a continuación (es un query de el año 2007 en el que se tiene la esperanza de vida y la población indexada por país)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1466fb47-75cc-44eb-880f-cab87172599e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = dataset[dataset['year'] == 2007].set_index('country')\n",
    "df = df[['lifeExp', 'pop']]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be52fdd-4ceb-4167-b5d9-b3595b80119c",
   "metadata": {},
   "source": [
    "- **Utiliza el método Min-Max** para normalizar los vectores de Esperanza de vida y de Población, una vez que apliquemos las funciones de similitud es mejor tener los vectores en las misma escala: [Ejemplo aquí](https://www.geeksforgeeks.org/data-normalization-with-pandas/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "219df90b-4913-42d9-96ee-761f543bed78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        country   lifeExp       pop\n",
      "11  Afghanistan  0.098046  0.024035\n",
      "23      Albania  0.856246  0.002579\n",
      "35      Algeria  0.760363  0.025130\n",
      "47       Angola  0.072528  0.009269\n",
      "59    Argentina  0.830589  0.030416\n",
      "Matriz de similitud coseno entre esperanza de vida y población:\n",
      "[[0.27973128]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# apply normalization\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "dataset = pd.read_csv(\"../data/gapminder_data_world_health.csv\")\n",
    "\n",
    "data_2007 = dataset[dataset['year'] == 2007]\n",
    "\n",
    "data_subset= data_2007[['country', 'lifeExp', 'pop']]\n",
    "\n",
    "# Normalizamos datos\n",
    "scaler = MinMaxScaler()\n",
    "data_subset.loc[:,['lifeExp', 'pop']] = scaler.fit_transform(data_subset[['lifeExp', 'pop']])\n",
    "\n",
    "print(data_subset.head())\n",
    "\n",
    "# datos normalizados a matrices\n",
    "lifeExp_vector = data_subset[['lifeExp']].values\n",
    "pop_vector = data_subset[['pop']].values\n",
    "\n",
    "# similitud coseno entre los vectores de esperanza de vida y población\n",
    "similarity_matrix = cosine_similarity(lifeExp_vector.T, pop_vector.T)\n",
    "\n",
    "print(\"Matriz de similitud coseno entre esperanza de vida y población:\")\n",
    "print(similarity_matrix)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#.loc[:,['lifeExp', si lo quito error:El SettingWithCopyWarning ocurre porque estás \n",
    "#modificando un DataFrame que es una vista de otro DataFrame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f428dd4-5cff-4f6d-9f4c-fbc79bd19261",
   "metadata": {},
   "source": [
    "---\n",
    "# EJERCICIO 5\n",
    "\n",
    "**Crea un un nuevo dataset con los 3 paises más cercanos a cada país**, es decir un **dataset de \n",
    "distancias**, el resultado que se busca es como se ve en la imagen. Utilizarás el subset normalizado (ejercicio 4) para ello y una de las funciones que creaste (manhattan, euclideana o coseno)\n",
    "\n",
    "![](../img/distancias.png)\n",
    "\n",
    "**Cómo crear el dataset de distancias?**\n",
    "- Por cada país, necesitas calcular la distancia entre él y todos los demás países en el DataFrame. Evitando comparar cada país consigo mismo.\n",
    "- Cada iteración corresponde a cada país comparado, el país al que se le calculó la distancia, y la distancia entre ambos. (hint: una lista de tuplas o diccionarios puede ser útil aquí)\n",
    "- Después de hacer todas las comparaciones, convierte los resultados en un DataFrame con tres columnas: `nodeA`, `nodeB`, `distance`.\n",
    "- Para cada país (nodeA), agrupa las distancias calculadas y ordénalas de menor a mayor. Se quiere unicamente los tres países más cercanos a cada país (distancias más pequeñas para cada país)\n",
    "- No olvides revisar los resultados una vez que tengas la tabla final con los 3 países más cercanos para cada país"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca3cb727-0f31-4838-91ab-2118238744eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        country   lifeExp       pop\n",
      "11  Afghanistan  0.098046  0.024035\n",
      "23      Albania  0.856246  0.002579\n",
      "35      Algeria  0.760363  0.025130\n",
      "47       Angola  0.072528  0.009269\n",
      "59    Argentina  0.830589  0.030416\n",
      "         nodeA                     nodeB  distance\n",
      "0  Afghanistan                  Zimbabwe  0.022782\n",
      "1  Afghanistan                    Angola  0.040284\n",
      "2  Afghanistan  Central African Republic  0.042111\n",
      "3      Albania                   Uruguay  0.001023\n",
      "4      Albania                   Reunion  0.002567\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## for loop in all countries applying 1 distance function\n",
    "## dataframe _____\n",
    "## top 3 distances: Zimbabwe,Angola y República central de Africa para Afganistan\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#original\n",
    "dataset = pd.read_csv(\"../data/gapminder_data_world_health.csv\")\n",
    "\n",
    "# año 2007\n",
    "data_subset = dataset[dataset['year'] == 2007][['country', 'lifeExp', 'pop']]\n",
    "\n",
    "#distancia Manhattan\n",
    "def manhattan_distance(vec1, vec2):\n",
    "    return np.sum(np.abs(vec1 - vec2))\n",
    "\n",
    "#Normalizamos\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "data_subset[['lifeExp', 'pop']] = scaler.fit_transform(data_subset[['lifeExp', 'pop']])\n",
    "\n",
    "print(data_subset.head())\n",
    "\n",
    "data_subset.to_csv('normalized_data_2007.csv', index=False) #para guardar csv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def manhattan_distance(vec1, vec2):\n",
    "    return np.sum(np.abs(vec1 - vec2))\n",
    "\n",
    "\n",
    "data_subset = pd.read_csv(\"normalized_data_2007.csv\")  #archivo normalizado\n",
    "\n",
    "\n",
    "lifeExp_vector = data_subset[['lifeExp']].values\n",
    "pop_vector = data_subset[['pop']].values\n",
    "\n",
    "#lista para almacenar las distancias\n",
    "distances = []\n",
    "\n",
    "for i, (lifeExp_i, pop_i) in enumerate(zip(lifeExp_vector, pop_vector)):\n",
    "    for j, (lifeExp_j, pop_j) in enumerate(zip(lifeExp_vector, pop_vector)):\n",
    "        if i != j:  #evitar que sean los mismos\n",
    "            distance = manhattan_distance(lifeExp_i, lifeExp_j) + manhattan_distance(pop_i, pop_j)\n",
    "            distances.append({\n",
    "                'nodeA': data_subset.iloc[i]['country'],\n",
    "                'nodeB': data_subset.iloc[j]['country'],\n",
    "                'distance': distance\n",
    "            })\n",
    "\n",
    "#DataFrame de distancias\n",
    "distances_df = pd.DataFrame(distances)\n",
    "\n",
    "# Encontrar los 3 países más cercanos para cada país\n",
    "closest_countries = distances_df.groupby('nodeA').apply(\n",
    "    lambda x: x.nsmallest(3, 'distance')\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(closest_countries.head())\n",
    "\n",
    "closest_countries.to_csv('closest_countries_manhattan.csv', index=False) #guardemos\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29045c2c-fa13-4dd2-b1fe-36425ba8ed5f",
   "metadata": {},
   "source": [
    "---\n",
    "# EJERCICIO 6\n",
    "\n",
    "Reproduce el siguiente script.   \n",
    "El script utiliza la libreria `networkx` y `plotly` para visualizar una gráfica de red (network plot) visualizando la distancia (similitud) entre los paises basado en esperanza de vida y población.  \n",
    "\n",
    "**Nota:** Si el dataframe del ejercicio anterior no es correcto, la visualización no va a funcionar.\n",
    "\n",
    "**Responde lo siguiente:**\n",
    "- Cuales son los países más similares a México?\n",
    "- Explica cuales serían las consideraciones éticas al decir que México es similar a esos países en el contexto de las variables `lifeExp` y `pop`, dando contexto de el año seleccionado y del significado de la funcion de similitud utilizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2811b909-687b-40a4-b72a-c5c970de0136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "distances = [\n",
    "    {'nodeA': 'Afghanistan', 'nodeB': 'Zimbabwe', 'distance': 0.022782},\n",
    "    {'nodeA': 'Afghanistan', 'nodeB': 'Angola', 'distance': 0.040284},\n",
    "    {'nodeA': 'Afghanistan', 'nodeB': 'Central African Republic', 'distance': 0.042111},\n",
    "    {'nodeA': 'Albania', 'nodeB': 'Uruguay', 'distance': 0.001023},\n",
    "    {'nodeA': 'Albania', 'nodeB': 'Reunion', 'distance': 0.002567},\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "df_network = pd.DataFrame(distances)\n",
    "print(df_network.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130f8a5b-2662-4421-a2c7-e5252daeb234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "#Empty graph object\n",
    "g = nx.Graph()\n",
    "\n",
    "# Adding all nodes\n",
    "g.add_nodes_from(list(df_network.nodeA.unique()))\n",
    "\n",
    "# Adding all edges\n",
    "edges_list = [(row[1][0],row[1][1],row[1][2]) for row in df_network.iterrows()]\n",
    "g.add_weighted_edges_from(edges_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b656ac48-9df3-4989-b303-1ddc99707d49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "pos = nx.spring_layout(g, dim=2, iterations=10, weight='weight', scale=2)\n",
    "\n",
    "# Create a DataFrame for nodes\n",
    "node_x = []\n",
    "node_y = []\n",
    "for node in g.nodes():\n",
    "    x, y = pos[node]\n",
    "    node_x.append(x)\n",
    "    node_y.append(y)\n",
    "\n",
    "# Create a DataFrame for edges\n",
    "edge_x = []\n",
    "edge_y = []\n",
    "for edge in g.edges():\n",
    "    x0, y0 = pos[edge[0]]\n",
    "    x1, y1 = pos[edge[1]]\n",
    "    edge_x.append(x0)\n",
    "    edge_x.append(x1)\n",
    "    edge_x.append(None)  # For a break between edges\n",
    "    edge_y.append(y0)\n",
    "    edge_y.append(y1)\n",
    "    edge_y.append(None)  # For a break between edges\n",
    "\n",
    "# Create the plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add edges to the plot\n",
    "fig.add_trace(go.Scatter(x=edge_x, y=edge_y,\n",
    "                         line=dict(width=0.5, color='gray'),\n",
    "                         hoverinfo='none',\n",
    "                         mode='lines'))\n",
    "\n",
    "# Add nodes to the plot\n",
    "fig.add_trace(go.Scatter(x=node_x, y=node_y,\n",
    "                         mode='markers+text',  # Show both markers and labels\n",
    "                         marker=dict(size=10, color='#9500ff'),\n",
    "                         text=[str(node) for node in g.nodes()],  # Add node labels\n",
    "                         textposition='top center',\n",
    "                         hoverinfo='text'))\n",
    "\n",
    "# Update layout for better aesthetics and set figure size\n",
    "fig.update_layout(\n",
    "    showlegend=False,\n",
    "    xaxis=dict(showgrid=False, zeroline=False),\n",
    "    yaxis=dict(showgrid=False, zeroline=False),\n",
    "    plot_bgcolor='white',\n",
    "    width=1200,  # Set the figure width\n",
    "    height=1500   # Set the figure height\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f8676a-e0b6-4721-bd82-336ae1b276a4",
   "metadata": {},
   "source": [
    "La gráfica debe quedar como se ve en la imagen.   \n",
    "![](../img/countries_similarities.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4de1c4-219e-42d1-8679-f70bce01b0d9",
   "metadata": {},
   "source": [
    "## 🎉🎉 Congrats!!  \n",
    "\n",
    "## You've finished the notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
